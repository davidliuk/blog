# 集成学习

## Bagging

Bagging 算法是一种集成学习的方法，它的基本思想是：通过构建并结合多个分类器来完成学习任务，最终将各个分类器的预测结果进行结合，得到最终的预测结果。Bagging算法的基本思想是：通过构建并结合多个分类器来完成学习任务，最终将各个分类器的预测结果进行结合，得到最终的预测结果。

## Boosting

 Boosting 算法是一种集成学习的方法，它的基本思想是将弱分类器组合成一个强分类器。Boosting算法的基本思想是：通过迭代的方式，每一次迭代都学习一个弱分类器，然后将这些弱分类器进行加权组合，得到最终的强分类器。Boosting算法的主要思想是：通过迭代的方式，每一次迭代都学习一个弱分类器，然后将这些弱分类器进行加权组合，得到最终的强分类器。

<!-- 对比Bagging和Boosting -->

## Bagging 和 Boosting 的区别

Bagging和Boosting都是集成学习的方法，它们的基本思想都是：通过构建并结合多个分类器来完成学习任务，最终将各个分类器的预测结果进行结合，得到最终的预测结果。

主要区别是：Bagging是并行的，Boosting是串行的。

## 集成学习的结合策略

### 平均法

平均法是一种简单的集成学习的结合策略，它的基本思想是：将各个分类器的预测结果进行简单的平均，得到最终的预测结果。

### 学习法

学习法是一种复杂的集成学习的结合策略，它的基本思想是：通过学习的方式，得到最终的预测结果。

### 投票法

投票法是一种简单的集成学习的结合策略，它的基本思想是：将各个分类器的预测结果进行简单的投票，得到最终的预测结果。

### 加权投票法

加权投票法是一种简单的集成学习的结合策略，它的基本思想是：将各个分类器的预测结果进行加权投票，得到最终的预测结果。

## AdaBoost

AdaBoost是一种基于Boosting的集成学习算法，它的基本思想是：通过迭代的方式，每一次迭代都学习一个弱分类器，然后将这些弱分类器进行加权组合，得到最终的强分类器。

