# Feature

离散特征

- 性别：男、女两种类别。
- 国籍：中国、美国、印度等200个国家
- 英文单词：常见的英文单词有几万个。
- 物品D：小红书有几亿篇笔记，每篇笔记有一个ID。
- 用户D：小红书有几亿个用户，每个用户有一个D。

---

离散特征处理

1. 建立字典：把类别映射成序号
   - 中国→1
   - 美国→2
   - 印度→3
2. 向量化：把序号映射成向量
   - One-hot 编码：把序号映射成高维稀疏向量。
   - Embedding：把序号映射成低维稠密向量。

## One-hot

例1：性别特征

- 性别：男、女两种类别。
- 字典：男→1，女→2。
- One-hot编码：用2维向量表示性别。
  - 未知→0→[0,0]
  - 男→1→[1,0]
  - 女→2→[0,1]

例2：国籍特征

- 国籍：中国、美国、印度等200种类别。
- 字典：中国→1，美国→2，印度→3，…
- One-hot编码：用200维稀疏向量表示国籍。
  - 未知→0→[0,0,0,0，…，0]
  - 中国→1→[1,0,0,0，…，0]
  - 美国→2→[0,1,0,0，…，0]
  - 印度→3→[0,0,1,0，…，0]

One-Hot编码的局限

- 例1：自然语言处理中，对单词做编码。
  - 英文有几万个常见单词。
  - 那么one-hot向量的维度是几万。
- 例2：推荐系统中，对物品D做编码。
  - 小红书有几亿篇笔记。
  - 那么one-hot向量的维度是几亿。

类别数量太大时，通常不用one-hot编码。

## Embedding

例1：国籍的Embedding

- 参数数量：向量维度×类别数量。
  - 设embedding得到的向量都是4维的。
  - 一共有200个国籍。
  - 参数数量=4×200=800。
- 编程实现：TensotFlow、PyTotch提供embedding层。
  - 参数以矩阵的形式保存，矩阵大小是向量维度×类别数量。
  - 输入是序号，比如“美国”的序号是2。
  - 输出是向量，比如“美国”对应参数矩阵的第2列。

例2：物品ID的Embedding

- 数据库里一共有10,000部电影。
- 任务是给用户推荐电影。
- 设embedding向量的维度是16o

Embedding层有多少参数？

- 参数数量=向量维度×类别数量=160,000

工业界会对embedding层做很多优化

![image-20250817221523681](https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250817221523681.png)

 Embedding=参数矩阵×One-Hot向量

![image-20250817221742432](https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250817221742432.png)

矩阵向量乘法，和全连接层很像

- 离散特征处理：one-hot编码、embedding。
- 类别数量很大时，用embedding。
  - Word embedding
  - 用户ID embedding
  - 物品ID embedding