# 参数附加方法

参数附加方法通过增加并训练新的附加参数或模块对大语言模型进行微调。参数附加方法按照附加位置可以分为三类：

- 加在输入
- 加在模型
- 加在输出

将额外参数附加到模型的输入
将额外的参数或模型添加到模
通过在解码时修改模型的输出
嵌入中，其中最经典的方法是
型的隐藏层中，其中经典的方
分布，其中经典方法是Proxy-
Prompt-tuning.
法有Prefix-.tuning、Adapter-
tuning.
Tuning等。

## 加在输入

加在输入的方法将额外参数附加到模型的输入嵌入(Embedding)中，其中最经典的方法是Prompt-tuning。

软提这些额外参数通常称之为软提示(Soft Prompt)。不同于手工编写的硬提示(Hard Prompt),软提示会在训练过程中被动态调整，其本质是可训练的、连续的嵌入。

文本序列进入大模型前，会先通过词表词表编码成Token,并通过嵌入矩阵的转化为向量序列，输入给大模型处理。 

Prompt-uning引入软提示作为模型输入的一部分，与实际的文本数据一起被送入模型。在微调过程中，仅软提示的参数会被更新。

![image-20250615230404171](https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250615230404171.png)

设置合适的软提示长度和合理初始化软提示对Prompt--tuning至关重要。

将额外参数附加到模型输入有以下优势：

- 内存效率高
- 多任务能力
- 缩放特性

## 加在模型

加在模型的方法将额外的参数或模型添加到预训练模型的隐藏层中，其中经典的方法有Prefix-tuning、Adapter-tuning等。

### Prefix-tuning 

Prefix-tuning和Prompt--tuning十分类似，但对软提示的处理有所不同。

- Prompt-tuning仅将软提示添加到输入嵌入中。
- Prefix-tuning将可训练前缀插入到输入嵌入以及注意力模块中。