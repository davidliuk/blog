# SVM

支持向量机



深度学习火起来以前，最火的，分类最好的算法就是 SVM 和随机森林



对于分界线上的元素，遵循公平性原则



线性分类器：可以画超平面去分类为两类

线性函数，计算简单，易于求解

间隔最大化：分类超平面和两类数据直接的间隔尽可能的大，两边都保持尽量远（保证公平性）



正样本、负样本



### 核函数

- 线性核函数
- 多项式核函数
- 高斯核函数



CNN：卷积神经网络

- 特征提取很

RNN：循环神经网络

- 容易遗忘以前的特征

LSTM：指长短期记忆人工神经网络

- 记忆好

GNN：图卷积网络



g(z)=-1, +1 （门函数）（如果是sigmoid，0的地方就是0有距离为0，不希望出现这样情况）

$h_\theta(x)=g(\theta^Tx)$

$h_{w,b}(x)=g(w^Tx+b)$

函数间隔：类似法线距离：

$\hat l^{{(i)}}=y^{{(i)}}(wx^{{(i)}}+b)$

（缺点：如果两个函数同样乘k，不会改变函数距离，但是他们位置确实变了，所以引入下面的几何间隔）

$\max\limits_{w,b}l,y^{(i)}(w^Tx^{(i)}+b)\ge l$

且$||w||=1$

公式三：
$$
\max\limits_{w,b}\frac{1}{2}||w||^2,\\
s.t.y^{(i)}(w^Tx^{(i)}+b)\ge l
$$






SVM是欧式距离（欧式空间）下最好的分类器

KKT条件

只和特征向量样本内积有关



