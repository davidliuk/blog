# 如何实现一个扫描全能王？

三个需求

- 找到图片中的纸张：边缘检测
- 将纸张修复展平并放在图像中间：透视变换
- 更进一步：如何识别图中文字？

## 文档扫描

1. 边缘检测
2. 获取纸张轮廓
3. 透视变换

## OCR

- CTPN 算法：检测文本位置
- CRNN 算法：识别文本内容

### CTPN 算法

> ECCV 2016提出的一种文字检测算法
>
> Z. Tian, W. Huang, T. He, P. He and Y. Qiao: Detecting Text in Natural Image with Connectionist Text Proposal Network, ECCV, 2016.

RPN（Region Proposal Network）方法（faster-rcnn）

文本通常都是从左往右写的（水平），并且字之间的宽度都大致相同固定宽度，来检测文本高度即可，但是如何应对变长序列呢？

本质上还是 RPN 方法（可参考 faster rcnn)，可将检测到的框拼在一起。

1.  使用 VGG16 的卷积阶段的网络层作为骨干网络，然后将图片输入 VGG16 网络中进行特征提取，生成特征图

2.  在 ① 中输出的特征图中滑动进行 3\*3 卷积，然后进行 im2col 操作，然后每次滑动都得到一个 3\*3通道数的特征向量，最后生成一个新的特征图，然后输入 BiLSTM 中进行序列特征提取，再传入全连接层中进一步提取特征

3.  在 ② 的全连接层后接 3 个全连接层分支，分别预测垂直坐标回归、分类得分、水平平移量回归

4. 将 ③ 中的预测垂直坐标回归和分类得分结果输入 RPN 中

#### 网络架构

VGG 提取特征，BiLSTM 融入上下文信息，基于 RPN 完成检测

二分类：文字/背景

VGG 网络的 4 次池化，后面不进行了

没用 resnet（因为这个工作相对不新，用的传统方法）

#### 任务

输出结果包括了三部分：2K 得分，2K 回归，1K 边界调整（相比于以前工作多的一部分，提升 2%）

边界调整能使得文本检测框效果更好，下列是调整后的结果：

#### 合并小框

检测到每一个小块文本区域还需拼接成完整的文本区域：

规则，分前向和后向两部分：

先前向走，对于 Xi,基于重合度(0.7)与位置距离（50 像素）找到 score 值最大的的 X,接下来再返向走（规则不变），比较两次得分值大小来判断序列。

### CRNN 算法

CNN + RNN

卷积和递归神经网络结合在一起：由图像得到文本

> 每个词都需要上下文信息，所以只有 CNN 是不合适的

首先 CNN 进行特征提取，接下来 RNN 进行序列特征提取，最后得出预测结果即可。

#### CTC 模块

对齐，对于不同长度、间隔，但是语意一样的问题，如何处理

以前的方法：都识别，然后去重，重复的只留一个

CTC：预测特殊字符，（空的或者延续长的音就变成特殊字符），然后识别的时候过滤掉。

卷积、池化（保持宽度不变长度减半）

#### 文本生成器

### 训练

#### 数据集



老师表示，zhaoge这个项目是满分的水平，有一定见解且解决了一些问题。

门限秘密共享



GoogleNet比VGG参数小得多、训练筷很多

## 数据获取





## 训练资源

AutoDL

https://blog.csdn.net/qq_43711697/article/details/111397308



12:14



15:38

主要是参与感，没有开发也可以很认可你的工作



