import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,a as l,o as n}from"./app-CGXHKXsa.js";const a={};function o(r,i){return n(),t("div",null,i[0]||(i[0]=[l('<h1 id="dit" tabindex="-1"><a class="header-anchor" href="#dit"><span>DiT</span></a></h1><p>传统扩散模型的问题</p><ol><li>背景崩坏</li><li>角色脸盲</li></ol><p>传统方法：U-Net</p><p>CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙</p><h2 id="dydit" tabindex="-1"><a class="header-anchor" href="#dydit"><span>DyDiT</span></a></h2><ol><li>时间步动态宽度（TDW），轻量级路由器</li><li>空间动态令牌（SDT）</li></ol><h2 id="mmdit" tabindex="-1"><a class="header-anchor" href="#mmdit"><span>MMDiT</span></a></h2><p>SD3</p><ul><li>DiT:架构从&quot;U-Net&quot;到”Transformer&#39;”的跨越</li><li>DyDiT:计算从“静态”到“动态”的优化</li><li>MMDT:模态从“单模态”到&quot;多模态深度交互”的升级</li></ul>',10)]))}const m=e(a,[["render",o],["__file","index.html.vue"]]),D=JSON.parse(`{"path":"/ai/gm/llm/dit/","title":"DiT","lang":"en-US","frontmatter":{"description":"DiT 传统扩散模型的问题 背景崩坏 角色脸盲 传统方法：U-Net CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙 DyDiT 时间步动态宽度（TDW），轻量级路由器 空间动态令牌（SDT） MMDiT SD3 DiT:架构从\\"U-Net\\"到”Transformer'”的跨越 DyDiT:计算从“静态”到“动态”的优化 MMDT:模态从“...","head":[["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/gm/llm/dit/"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"DiT"}],["meta",{"property":"og:description","content":"DiT 传统扩散模型的问题 背景崩坏 角色脸盲 传统方法：U-Net CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙 DyDiT 时间步动态宽度（TDW），轻量级路由器 空间动态令牌（SDT） MMDiT SD3 DiT:架构从\\"U-Net\\"到”Transformer'”的跨越 DyDiT:计算从“静态”到“动态”的优化 MMDT:模态从“..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-10-26T05:16:21.000Z"}],["meta",{"property":"article:modified_time","content":"2025-10-26T05:16:21.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"DiT\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-10-26T05:16:21.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"]]},"headers":[{"level":2,"title":"DyDiT","slug":"dydit","link":"#dydit","children":[]},{"level":2,"title":"MMDiT","slug":"mmdit","link":"#mmdit","children":[]}],"git":{"createdTime":1761441676000,"updatedTime":1761455781000,"contributors":[{"name":"dawei.liu","email":"dawei.liu@bytedance.com","commits":1}]},"readingTime":{"minutes":0.4,"words":119},"filePathRelative":"ai/gm/llm/dit/README.md","localizedDate":"October 26, 2025","excerpt":"\\n<p>传统扩散模型的问题</p>\\n<ol>\\n<li>背景崩坏</li>\\n<li>角色脸盲</li>\\n</ol>\\n<p>传统方法：U-Net</p>\\n<p>CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙</p>\\n<h2>DyDiT</h2>\\n<ol>\\n<li>时间步动态宽度（TDW），轻量级路由器</li>\\n<li>空间动态令牌（SDT）</li>\\n</ol>\\n<h2>MMDiT</h2>\\n<p>SD3</p>\\n<ul>\\n<li>DiT:架构从\\"U-Net\\"到”Transformer'”的跨越</li>\\n<li>DyDiT:计算从“静态”到“动态”的优化</li>\\n<li>MMDT:模态从“单模态”到\\"多模态深度交互”的升级</li>\\n</ul>","autoDesc":true}`);export{m as comp,D as data};
