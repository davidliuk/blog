import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,a as d,o as n}from"./app-z8Dpj-As.js";const a={};function o(i,t){return n(),r("div",null,t[0]||(t[0]=[d('<h1 id="representations-benchmarks-and-learning-paradigms" tabindex="-1"><a class="header-anchor" href="#representations-benchmarks-and-learning-paradigms"><span>Representations, Benchmarks, and Learning Paradigms</span></a></h1><h2 id="table-of-contents" tabindex="-1"><a class="header-anchor" href="#table-of-contents"><span>Table of Contents</span></a></h2><h2 id="ğŸ“š-3d-datasets-summary" tabindex="-1"><a class="header-anchor" href="#ğŸ“š-3d-datasets-summary"><span><a href="#3d-datasets-summary">ğŸ“š 3D Datasets Summary</a></span></a></h2><table><thead><tr><th>Dataset</th><th>Modality</th><th>Year</th><th>Granularity</th><th>Tasks</th><th>Project</th><th>Size</th></tr></thead><tbody><tr><td><a href="https://arxiv.org/pdf/2401.12592" target="_blank" rel="noopener noreferrer">WildRGB-D</a></td><td>RGB-D, Instance Masks, Camera Pose, Point Cloud</td><td>2024</td><td>Object</td><td>View Synthesis, Pose Estimation, 6D Object Tracking, 3D Reconstruction</td><td><a href="https://wildrgbd.github.io/" target="_blank" rel="noopener noreferrer">Website</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2211.15692" target="_blank" rel="noopener noreferrer">H3WB</a></td><td>RGB, 2D+3D Whole-body Keypoints, Camera Pose</td><td>2022</td><td>Human Body</td><td>3D Pose Estimation</td><td><a href="https://github.com/wholebody3d/wholebody3d" target="_blank" rel="noopener noreferrer">Website</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2312.16256" target="_blank" rel="noopener noreferrer">DL3DV-10K</a></td><td>RGB video frames, Camera Pose, Scene Meta</td><td>2023</td><td>Scene</td><td>Novel View Synthesis, NeRF Pretraining</td><td><a href="https://dl3dv-10k.github.io/DL3DV-10K/" target="_blank" rel="noopener noreferrer">Website</a></td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2011.12954" target="_blank" rel="noopener noreferrer">RELLIS-3D</a></td><td>RGB, LiDAR point cloud, Stereo, GPS/IMU, Camera+LiDAR Pose, Semantic Labels</td><td>2020</td><td>Outdoor scenes</td><td>3D Semantic Segmentation, Sensor Fusion, Autonomous Navigation</td><td><a href="https://www.unmannedlab.org/research/RELLIS-3D" target="_blank" rel="noopener noreferrer">Website</a></td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2110.06199" target="_blank" rel="noopener noreferrer">Amazon Berkeley Objects</a></td><td>Multi View, Camera Intrinsics &amp; PBR Materials, 3D Mesh</td><td>2021</td><td>Object</td><td>3D Reconstruction, Multi-view Retrieval, Material Estimation</td><td><a href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html" target="_blank" rel="noopener noreferrer">Website</a></td><td></td></tr><tr><td><a href="https://www.research.autodesk.com/app/uploads/2023/03/Fusion_360_Gallery__A_Dataset_and_Environment_for_Programmatic_CAD_Construction_from_Human_Design_Sequences.pdf_recB1A7wJLthITzJo.pdf" target="_blank" rel="noopener noreferrer">Fusion 360 Gallery Dataset</a></td><td>Parametric CAD (Bâ€‘Rep) models + 2D operation sequences + 3D meshes + assembly/joint info</td><td>2021</td><td>Object</td><td>3D reconstruction, segmentation, assembly prediction, sequential modeling</td><td><a href="https://github.com/AutodeskAILab/Fusion360GalleryDataset" target="_blank" rel="noopener noreferrer">Github</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2109.00512" target="_blank" rel="noopener noreferrer">CO3Dv2</a></td><td>Multi-view RGB, Camera Pose, Ground-truth 3D Point Cloud</td><td>2021</td><td>Object</td><td>Novel View Synthesis, Category-level 3D Reconstruction</td><td><a href="https://github.com/facebookresearch/co3d" target="_blank" rel="noopener noreferrer">Github</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2203.03570" target="_blank" rel="noopener noreferrer">Kubric</a></td><td>Multi-view RGB, Camera Pose, Semantic Segmentation, Semantic Point Cloud</td><td>2022</td><td>Indoor Scene</td><td>Semantic Mapping, 2.5D Reconstruction, View-consistent Semantics</td><td><a href="https://github.com/google-research/kubric" target="_blank" rel="noopener noreferrer">Github</a></td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2011.02523" target="_blank" rel="noopener noreferrer">HyperSim</a></td><td>RGB + Depth + Pose + Segmentation + Material + Lighting + 3D Mesh</td><td>2021</td><td>Indoor Scene</td><td>Multi-task Scene Understanding: Semantic Segmentation, 3D Shape Prediction, Inverse Rendering</td><td><a href="https://github.com/apple/ml-hypersim" target="_blank" rel="noopener noreferrer">Github</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2106.14405" target="_blank" rel="noopener noreferrer">Habitat 2.0</a></td><td>RGB, Depth, Semantic Segmentation</td><td>2021</td><td>Object</td><td>Pick, Place, Navigate, Open, Close, Rearrange</td><td><a href="https://sites.google.com/view/habitat2" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2003.13989" target="_blank" rel="noopener noreferrer">FaceScape</a></td><td>FaceScape</td><td>2020</td><td>Human Face</td><td>Classification, Segmentation, Reconstruction, Completion, Recognition</td><td><a href="https://github.com/zhuhao-nju/facescape" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://vladlen.info/papers/3d-scan-dataset.pdf" target="_blank" rel="noopener noreferrer">A Large Dataset of Object Scans</a></td><td>RGBD / Point Cloud</td><td>2020</td><td>Object</td><td>Object Scanning, 3D Reconstruction, Object Categorization</td><td><a href="https://github.com/isl-org/redwood-3dscan" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Fu_3D-FRONT_3D_Furnished_Rooms_With_layOuts_and_semaNTics_ICCV_2021_paper.pdf?utm_source=chatgpt.com" target="_blank" rel="noopener noreferrer">3D-FRONT</a></td><td>Room Layout + Meshes</td><td>2020</td><td>Scene</td><td>Scene Understanding, Layout Analysis, Object Arrangement</td><td><a href="https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2009.09633.pdf" target="_blank" rel="noopener noreferrer">3D-FUTURE</a></td><td>Furniture CAD with Textures</td><td>2020</td><td>Object</td><td>Navigation, Exploration, Interaction</td><td><a href="https://tianchi.aliyun.com/specials/promotion/alibaba-3d-future" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540494.pdf" target="_blank" rel="noopener noreferrer">Structured3D</a></td><td>Photo-realistic + Annotations</td><td>2020</td><td>Scene</td><td>Reconstruction, Segmentation, Object Detection</td><td><a href="https://structured3d-dataset.org/#download" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470579.pdf" target="_blank" rel="noopener noreferrer">Mapillary</a></td><td>Image + Depth Map</td><td>2020</td><td>Scene</td><td>Reconstruction, Semantics, Viewpoint Estimation</td><td><a href="https://www.mapillary.com/dataset/depth" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Koch_ABC_A_Big_CAD_Model_Dataset_for_Geometric_Deep_Learning_CVPR_2019_paper.pdf" target="_blank" rel="noopener noreferrer">ABC</a></td><td>CAD</td><td>2019</td><td>Object</td><td>Shape Analysis, Segmentation, Surface Fitting</td><td><a href="https://deep-geometry.github.io/abc-dataset" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1911.10127" target="_blank" rel="noopener noreferrer">BlendedMVS</a></td><td>Multi-view</td><td>2019</td><td>Object</td><td>Reconstruction, Alignment, Evaluation</td><td><a href="https://github.com/YoYo000/BlendedMVS" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1906.05797" target="_blank" rel="noopener noreferrer">Replica</a></td><td>Dense Mesh + HDR Texture + Semantic/Instance Labels + Mirror/Glass</td><td>2019</td><td>Indoor Scene</td><td>Scene Graph Generation, Object Detection, Relationship Modeling</td><td><a href="https://github.com/facebookresearch/Replica-Dataset" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1805.09817" target="_blank" rel="noopener noreferrer">RealEstate10K</a></td><td>Camera Poses Corresponding to Frames</td><td>2018</td><td>Scene</td><td>Part Segmentation, Hierarchical Labeling, Shape Understanding</td><td><a href="https://google.github.io/realestate10k/" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://www.cs.cornell.edu/projects/megadepth/paper.pdf" target="_blank" rel="noopener noreferrer">MegaDepth</a></td><td>RGBD, Camera Pose, Segment Labels</td><td>2018</td><td>Scene</td><td>Multisensory Perception, Object Interaction, Representation Learning</td><td><a href="https://www.cs.cornell.edu/projects/megadepth/" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1702.04405" target="_blank" rel="noopener noreferrer">ScanNet</a></td><td>RGB-D</td><td>2017</td><td>Indoor Scene</td><td>Feature Matching, Registration, 3D Reconstruction</td><td><a href="http://www.scan-net.org/" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1605.04797" target="_blank" rel="noopener noreferrer">Thingi10K</a></td><td>Triangle Mesh</td><td>2016</td><td>Object</td><td>Scene Understanding, Semantic Segmentation, Layout Prediction</td><td><a href="https://github.com/Thingi10K/Thingi10K" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://isprs-annals.copernicus.org/articles/IV-1-W1/91/2017/isprs-annals-IV-1-W1-91-2017.pdf" target="_blank" rel="noopener noreferrer">Semantic3D</a></td><td>Point Cloud + Classification</td><td>2016</td><td>Scene</td><td>Point Cloud Classification, Semantic Segmentation</td><td><a href="http://www.semantic3d.net/" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://www.saikit.org/static/projects/sceneNN/home/pdf/dataset_3dv16.pdf" target="_blank" rel="noopener noreferrer">SceneNN / ObjectNN</a></td><td>RGB-D Indoor Scenes</td><td>2016</td><td>Scene</td><td>Multi-view Fusion, 3D Reconstruction, Semantic Segmentation</td><td><a href="https://hkust-vgd.github.io/scenenn/" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1512.03012.pdf" target="_blank" rel="noopener noreferrer">ShapeNet</a></td><td>3D Mesh + Semantic</td><td>2015</td><td>Object</td><td>Single-view Reconstruction, Multi-view Reconstruction</td><td><a href="https://shapenet.org/" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1406.5670.pdf" target="_blank" rel="noopener noreferrer">ModelNet</a></td><td>CAD Models</td><td>2015</td><td>Object</td><td>Classification, Segmentation, Retrieval, Reconstruction</td><td><a href="http://modelnet.cs.princeton.edu/#" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1511.05175" target="_blank" rel="noopener noreferrer">PASCAL3D+</a></td><td>CAD</td><td>2014</td><td>Object</td><td>Scene Understanding, Object Detection, Semantic Segmentation</td><td><a href="https://cvgl.stanford.edu/resources.html" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/1804.00650" target="_blank" rel="noopener noreferrer">DeepMVS</a></td><td>RGB images</td><td>2018</td><td>Scene</td><td>CAD Alignment, 3D Matching, Pose Estimation</td><td><a href="https://phuang17.github.io/DeepMVS/mvs-synth.html" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2307.15055" target="_blank" rel="noopener noreferrer">PointOdyssey</a></td><td>3D Scenes</td><td>2023</td><td>Scene</td><td>3D Generation, Multimodal Learning, Simulation</td><td><a href="https://pointodyssey.com/" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2001.10773" target="_blank" rel="noopener noreferrer">Virtual KITTI</a></td><td>Synthetic Video</td><td>2020</td><td>Scene</td><td>6D Pose Estimation, Object Detection, Benchmarking</td><td><a href="https://gist.github.com/alwynmathew/114a060319d268d512ebe2e0b3781d0f?utm_source=chatgpt.com" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2403.13064" target="_blank" rel="noopener noreferrer">Aria Synthetic Environments</a></td><td>RGB + LiDAR</td><td>2024</td><td>Scene</td><td>Open-vocabulary Detection, LiDAR Region Merging, Long-tailed Object Detection</td><td><a href="https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_download_dataset?utm_source=chatgpt.com" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2306.06362" target="_blank" rel="noopener noreferrer">Aria Digital Twin</a></td><td>RGB + Depth + Audio</td><td>2023</td><td>Scene</td><td>3D Question Answering, Spatial Reasoning, Scene Understanding</td><td><a href="https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset?utm_source=chatgpt.com" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr><tr><td><a href="https://arxiv.org/pdf/2304.00501" target="_blank" rel="noopener noreferrer">Objaverse</a></td><td>3D Mesh + Text</td><td>2023</td><td>Object</td><td>3D Asset Collection, Annotation, Multimodal Learning</td><td><a href="https://github.com/allenai/objaverse-xl" target="_blank" rel="noopener noreferrer">Link</a></td><td></td></tr></tbody></table><p>ğŸ“ <em>Modality includes available signals like RGB, Depth, Pose, Segmentation, Flow, Mesh, Action...</em></p><h2 id="modalities-of-3d-datasets" tabindex="-1"><a class="header-anchor" href="#modalities-of-3d-datasets"><span>Modalities of 3D datasets</span></a></h2><table><thead><tr><th>Dataset</th><th>RGB-D</th><th>Point Cloud</th><th>Mesh</th><th>Multi-view</th><th>Implicit Field</th><th>Year</th></tr></thead><tbody><tr><td>WildRGB-D</td><td>âœ…</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>2024</td></tr><tr><td>H3WB</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>2022</td></tr><tr><td>DL3DV-10K</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>2023</td></tr><tr><td>RELLIS-3D</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>2020</td></tr><tr><td>Amazon Berkeley Objects</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âœ…</td><td>âŒ</td><td>2021</td></tr><tr><td>Fusion 360 Gallery Dataset</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>CO3Dv2</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td></td></tr><tr><td>Kubric</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td></td></tr><tr><td>HyperSim</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>Habitat 2.0</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>FaceScape</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>A Large Dataset of Object Scans</td><td>âœ…</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>3D-FRONT</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>3D-FUTURE</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>Structured3D</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>Mapillary</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>ABC</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td></td></tr><tr><td>BlendedMVS</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td></td></tr><tr><td>Replica</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>RealEstate10K</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td></td></tr><tr><td>MegaDepth</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td></td></tr><tr><td>ScanNet</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>Thingi10K</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td></td></tr><tr><td>Semantic3D</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>SceneNN / ObjectNN</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>ShapeNet</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>ModelNet</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>PASCAL3D+</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>DeepMVS</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td></td></tr><tr><td>PointOdyssey</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>Virtual KITTI</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td></td></tr><tr><td>Aria Synthetic Environments</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>Aria Digital Twin</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td></td></tr><tr><td>Objaverse</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td></td></tr><tr><td>GigaHands</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td></td></tr><tr><td>InteriorGS</td><td>âŒ</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âœ…</td><td></td></tr><tr><td>AnyHome</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td></td></tr><tr><td>DIVA-360</td><td>âŒ</td><td>âŒ</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td></td></tr><tr><td>StrobeNet</td><td>âŒ</td><td>âœ…</td><td>âŒ</td><td>âœ…</td><td>âœ…</td><td></td></tr></tbody></table><h2 id="âš’ï¸-applications" tabindex="-1"><a class="header-anchor" href="#âš’ï¸-applications"><span>âš’ï¸ Applications</span></a></h2>',8)]))}const p=e(a,[["render",o],["__file","repo.html.vue"]]),c=JSON.parse(`{"path":"/ai/3dv/repo.html","title":"Representations, Benchmarks, and Learning Paradigms","lang":"en-US","frontmatter":{"description":"Representations, Benchmarks, and Learning Paradigms ğŸ“š 3D Datasets Summary ğŸ“ Modality includes available signals like RGB, Depth, Pose, Segmentation, Flow, Mesh, Action... Moda...","head":[["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/3dv/repo.html"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"Representations, Benchmarks, and Learning Paradigms"}],["meta",{"property":"og:description","content":"Representations, Benchmarks, and Learning Paradigms ğŸ“š 3D Datasets Summary ğŸ“ Modality includes available signals like RGB, Depth, Pose, Segmentation, Flow, Mesh, Action... Moda..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-10-26T01:21:16.000Z"}],["meta",{"property":"article:modified_time","content":"2025-10-26T01:21:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Representations, Benchmarks, and Learning Paradigms\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-10-26T01:21:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"]]},"headers":[{"level":2,"title":"Table of Contents","slug":"table-of-contents","link":"#table-of-contents","children":[]},{"level":2,"title":"ğŸ“š 3D Datasets Summary","slug":"ğŸ“š-3d-datasets-summary","link":"#ğŸ“š-3d-datasets-summary","children":[]},{"level":2,"title":"Modalities of 3D datasets","slug":"modalities-of-3d-datasets","link":"#modalities-of-3d-datasets","children":[]},{"level":2,"title":"âš’ï¸ Applications","slug":"âš’ï¸-applications","link":"#âš’ï¸-applications","children":[]}],"git":{"createdTime":1761441676000,"updatedTime":1761441676000,"contributors":[{"name":"dawei.liu","email":"dawei.liu@bytedance.com","commits":1}]},"readingTime":{"minutes":2.74,"words":821},"filePathRelative":"ai/3dv/repo.md","localizedDate":"October 26, 2025","excerpt":"\\n\\n<h2><a class=\\"header-anchor\\" href=\\"#ğŸ“š-3d-datasets-summary\\"><span></span></a><a href=\\"#3d-datasets-summary\\">ğŸ“š 3D Datasets Summary</a></h2>\\n<table>\\n<thead>\\n<tr>\\n<th>Dataset</th>\\n<th>Modality</th>\\n<th>Year</th>\\n<th>Granularity</th>\\n<th>Tasks</th>\\n<th>Project</th>\\n<th>Size</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2401.12592\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">WildRGB-D</a></td>\\n<td>RGB-D, Instance Masks, Camera Pose, Point Cloud</td>\\n<td>2024</td>\\n<td>Object</td>\\n<td>View Synthesis, Pose Estimation, 6D Object Tracking, 3D Reconstruction</td>\\n<td><a href=\\"https://wildrgbd.github.io/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Website</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2211.15692\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">H3WB</a></td>\\n<td>RGB, 2D+3D Whole-body Keypoints, Camera Pose</td>\\n<td>2022</td>\\n<td>Human Body</td>\\n<td>3D Pose Estimation</td>\\n<td><a href=\\"https://github.com/wholebody3d/wholebody3d\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Website</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2312.16256\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">DL3DV-10K</a></td>\\n<td>RGB video frames, Camera Pose, Scene Meta</td>\\n<td>2023</td>\\n<td>Scene</td>\\n<td>Novel View Synthesis, NeRF Pretraining</td>\\n<td><a href=\\"https://dl3dv-10k.github.io/DL3DV-10K/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Website</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/abs/2011.12954\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RELLIS-3D</a></td>\\n<td>RGB, LiDAR point cloud, Stereo, GPS/IMU, Camera+LiDAR Pose, Semantic Labels</td>\\n<td>2020</td>\\n<td>Outdoor scenes</td>\\n<td>3D Semantic Segmentation, Sensor Fusion, Autonomous Navigation</td>\\n<td><a href=\\"https://www.unmannedlab.org/research/RELLIS-3D\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Website</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/abs/2110.06199\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Amazon Berkeley Objects</a></td>\\n<td>Multi View, Camera Intrinsics &amp; PBR Materials, 3D Mesh</td>\\n<td>2021</td>\\n<td>Object</td>\\n<td>3D Reconstruction, Multi-view Retrieval, Material Estimation</td>\\n<td><a href=\\"https://amazon-berkeley-objects.s3.amazonaws.com/index.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Website</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://www.research.autodesk.com/app/uploads/2023/03/Fusion_360_Gallery__A_Dataset_and_Environment_for_Programmatic_CAD_Construction_from_Human_Design_Sequences.pdf_recB1A7wJLthITzJo.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Fusion 360 Gallery Dataset</a></td>\\n<td>Parametric CAD (Bâ€‘Rep) models + 2D operation sequences + 3D meshes + assembly/joint info</td>\\n<td>2021</td>\\n<td>Object</td>\\n<td>3D reconstruction, segmentation, assembly prediction, sequential modeling</td>\\n<td><a href=\\"https://github.com/AutodeskAILab/Fusion360GalleryDataset\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Github</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2109.00512\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">CO3Dv2</a></td>\\n<td>Multi-view RGB, Camera Pose, Ground-truth 3D Point Cloud</td>\\n<td>2021</td>\\n<td>Object</td>\\n<td>Novel View Synthesis, Category-level 3D Reconstruction</td>\\n<td><a href=\\"https://github.com/facebookresearch/co3d\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Github</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2203.03570\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Kubric</a></td>\\n<td>Multi-view RGB, Camera Pose, Semantic Segmentation, Semantic Point Cloud</td>\\n<td>2022</td>\\n<td>Indoor Scene</td>\\n<td>Semantic Mapping, 2.5D Reconstruction, View-consistent Semantics</td>\\n<td><a href=\\"https://github.com/google-research/kubric\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Github</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/abs/2011.02523\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">HyperSim</a></td>\\n<td>RGB + Depth + Pose + Segmentation + Material + Lighting + 3D Mesh</td>\\n<td>2021</td>\\n<td>Indoor Scene</td>\\n<td>Multi-task Scene Understanding: Semantic Segmentation, 3D Shape Prediction, Inverse Rendering</td>\\n<td><a href=\\"https://github.com/apple/ml-hypersim\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Github</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2106.14405\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Habitat 2.0</a></td>\\n<td>RGB, Depth, Semantic Segmentation</td>\\n<td>2021</td>\\n<td>Object</td>\\n<td>Pick, Place, Navigate, Open, Close, Rearrange</td>\\n<td><a href=\\"https://sites.google.com/view/habitat2\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2003.13989\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">FaceScape</a></td>\\n<td>FaceScape</td>\\n<td>2020</td>\\n<td>Human Face</td>\\n<td>Classification, Segmentation, Reconstruction, Completion, Recognition</td>\\n<td><a href=\\"https://github.com/zhuhao-nju/facescape\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://vladlen.info/papers/3d-scan-dataset.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">A Large Dataset of Object Scans</a></td>\\n<td>RGBD / Point Cloud</td>\\n<td>2020</td>\\n<td>Object</td>\\n<td>Object Scanning, 3D Reconstruction, Object Categorization</td>\\n<td><a href=\\"https://github.com/isl-org/redwood-3dscan\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://openaccess.thecvf.com/content/ICCV2021/papers/Fu_3D-FRONT_3D_Furnished_Rooms_With_layOuts_and_semaNTics_ICCV_2021_paper.pdf?utm_source=chatgpt.com\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">3D-FRONT</a></td>\\n<td>Room Layout + Meshes</td>\\n<td>2020</td>\\n<td>Scene</td>\\n<td>Scene Understanding, Layout Analysis, Object Arrangement</td>\\n<td><a href=\\"https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2009.09633.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">3D-FUTURE</a></td>\\n<td>Furniture CAD with Textures</td>\\n<td>2020</td>\\n<td>Object</td>\\n<td>Navigation, Exploration, Interaction</td>\\n<td><a href=\\"https://tianchi.aliyun.com/specials/promotion/alibaba-3d-future\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540494.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Structured3D</a></td>\\n<td>Photo-realistic + Annotations</td>\\n<td>2020</td>\\n<td>Scene</td>\\n<td>Reconstruction, Segmentation, Object Detection</td>\\n<td><a href=\\"https://structured3d-dataset.org/#download\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470579.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Mapillary</a></td>\\n<td>Image + Depth Map</td>\\n<td>2020</td>\\n<td>Scene</td>\\n<td>Reconstruction, Semantics, Viewpoint Estimation</td>\\n<td><a href=\\"https://www.mapillary.com/dataset/depth\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://openaccess.thecvf.com/content_CVPR_2019/papers/Koch_ABC_A_Big_CAD_Model_Dataset_for_Geometric_Deep_Learning_CVPR_2019_paper.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">ABC</a></td>\\n<td>CAD</td>\\n<td>2019</td>\\n<td>Object</td>\\n<td>Shape Analysis, Segmentation, Surface Fitting</td>\\n<td><a href=\\"https://deep-geometry.github.io/abc-dataset\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1911.10127\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">BlendedMVS</a></td>\\n<td>Multi-view</td>\\n<td>2019</td>\\n<td>Object</td>\\n<td>Reconstruction, Alignment, Evaluation</td>\\n<td><a href=\\"https://github.com/YoYo000/BlendedMVS\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1906.05797\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Replica</a></td>\\n<td>Dense Mesh + HDR Texture + Semantic/Instance Labels + Mirror/Glass</td>\\n<td>2019</td>\\n<td>Indoor Scene</td>\\n<td>Scene Graph Generation, Object Detection, Relationship Modeling</td>\\n<td><a href=\\"https://github.com/facebookresearch/Replica-Dataset\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1805.09817\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RealEstate10K</a></td>\\n<td>Camera Poses Corresponding to Frames</td>\\n<td>2018</td>\\n<td>Scene</td>\\n<td>Part Segmentation, Hierarchical Labeling, Shape Understanding</td>\\n<td><a href=\\"https://google.github.io/realestate10k/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://www.cs.cornell.edu/projects/megadepth/paper.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">MegaDepth</a></td>\\n<td>RGBD, Camera Pose, Segment Labels</td>\\n<td>2018</td>\\n<td>Scene</td>\\n<td>Multisensory Perception, Object Interaction, Representation Learning</td>\\n<td><a href=\\"https://www.cs.cornell.edu/projects/megadepth/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1702.04405\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">ScanNet</a></td>\\n<td>RGB-D</td>\\n<td>2017</td>\\n<td>Indoor Scene</td>\\n<td>Feature Matching, Registration, 3D Reconstruction</td>\\n<td><a href=\\"http://www.scan-net.org/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1605.04797\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Thingi10K</a></td>\\n<td>Triangle Mesh</td>\\n<td>2016</td>\\n<td>Object</td>\\n<td>Scene Understanding, Semantic Segmentation, Layout Prediction</td>\\n<td><a href=\\"https://github.com/Thingi10K/Thingi10K\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://isprs-annals.copernicus.org/articles/IV-1-W1/91/2017/isprs-annals-IV-1-W1-91-2017.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Semantic3D</a></td>\\n<td>Point Cloud + Classification</td>\\n<td>2016</td>\\n<td>Scene</td>\\n<td>Point Cloud Classification, Semantic Segmentation</td>\\n<td><a href=\\"http://www.semantic3d.net/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://www.saikit.org/static/projects/sceneNN/home/pdf/dataset_3dv16.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">SceneNN / ObjectNN</a></td>\\n<td>RGB-D Indoor Scenes</td>\\n<td>2016</td>\\n<td>Scene</td>\\n<td>Multi-view Fusion, 3D Reconstruction, Semantic Segmentation</td>\\n<td><a href=\\"https://hkust-vgd.github.io/scenenn/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1512.03012.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">ShapeNet</a></td>\\n<td>3D Mesh + Semantic</td>\\n<td>2015</td>\\n<td>Object</td>\\n<td>Single-view Reconstruction, Multi-view Reconstruction</td>\\n<td><a href=\\"https://shapenet.org/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1406.5670.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">ModelNet</a></td>\\n<td>CAD Models</td>\\n<td>2015</td>\\n<td>Object</td>\\n<td>Classification, Segmentation, Retrieval, Reconstruction</td>\\n<td><a href=\\"http://modelnet.cs.princeton.edu/#\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1511.05175\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">PASCAL3D+</a></td>\\n<td>CAD</td>\\n<td>2014</td>\\n<td>Object</td>\\n<td>Scene Understanding, Object Detection, Semantic Segmentation</td>\\n<td><a href=\\"https://cvgl.stanford.edu/resources.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/1804.00650\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">DeepMVS</a></td>\\n<td>RGB images</td>\\n<td>2018</td>\\n<td>Scene</td>\\n<td>CAD Alignment, 3D Matching, Pose Estimation</td>\\n<td><a href=\\"https://phuang17.github.io/DeepMVS/mvs-synth.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2307.15055\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">PointOdyssey</a></td>\\n<td>3D Scenes</td>\\n<td>2023</td>\\n<td>Scene</td>\\n<td>3D Generation, Multimodal Learning, Simulation</td>\\n<td><a href=\\"https://pointodyssey.com/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2001.10773\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Virtual KITTI</a></td>\\n<td>Synthetic Video</td>\\n<td>2020</td>\\n<td>Scene</td>\\n<td>6D Pose Estimation, Object Detection, Benchmarking</td>\\n<td><a href=\\"https://gist.github.com/alwynmathew/114a060319d268d512ebe2e0b3781d0f?utm_source=chatgpt.com\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2403.13064\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Aria Synthetic Environments</a></td>\\n<td>RGB + LiDAR</td>\\n<td>2024</td>\\n<td>Scene</td>\\n<td>Open-vocabulary Detection, LiDAR Region Merging, Long-tailed Object Detection</td>\\n<td><a href=\\"https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_download_dataset?utm_source=chatgpt.com\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2306.06362\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Aria Digital Twin</a></td>\\n<td>RGB + Depth + Audio</td>\\n<td>2023</td>\\n<td>Scene</td>\\n<td>3D Question Answering, Spatial Reasoning, Scene Understanding</td>\\n<td><a href=\\"https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset?utm_source=chatgpt.com\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td><a href=\\"https://arxiv.org/pdf/2304.00501\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Objaverse</a></td>\\n<td>3D Mesh + Text</td>\\n<td>2023</td>\\n<td>Object</td>\\n<td>3D Asset Collection, Annotation, Multimodal Learning</td>\\n<td><a href=\\"https://github.com/allenai/objaverse-xl\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Link</a></td>\\n<td></td>\\n</tr>\\n</tbody>\\n</table>","autoDesc":true}`);export{p as comp,c as data};
