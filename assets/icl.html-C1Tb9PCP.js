import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,a as l,o as n}from"./app-BZLta1H5.js";const p={};function o(a,t){return n(),i("div",null,[...t[0]||(t[0]=[l('<h1 id="in-context-learning-上下文学习" tabindex="-1"><a class="header-anchor" href="#in-context-learning-上下文学习"><span>In-Context Learning 上下文学习</span></a></h1><p>上下文学习是大语言模型一种新的学习范式，它通过构造特定的Prompt,来使得语言模型理解并学习下游任务。相比于传统的监督微调，其不需要更新模型参数可以快速适应下游任务。</p><p>上下文学习通过任务说明，演示示例等信息引导模型输出，快速适应新任务，使语言模型即服务成为可能。监督微调需要构造训练集，通过更新模型参数来适应下游任务，效果更好，但是成本高。</p><h3 id="为什么有效" tabindex="-1"><a class="header-anchor" href="#为什么有效"><span>为什么有效</span></a></h3><p>大语言模型在预训练阶段从大量文本中学习潜在的概念。当运用上下文学习进行推理时，其借助任务说明或演示示例来“锚定”其在预训练期间所习得的相关概念，从而进行上下文学习，并对问题进行预测。</p><p>ICL 分类</p><p>上下文学习的分类按照示例数量的不同，上下文学习可以分为三类：</p><ul><li>零样本(Zero-shot)上下文学习</li><li>单样本(One-shot)上下文学习</li><li>少样本(Few-shot)上下文学习。</li></ul><p>演示示例选择</p><p>演示示例选择的两个主要依据是相似性和多样性。鉴于不同方法对示例选择依据的侧重有所不同，现有的示例选择策略大致归纳为三类：直接检索、聚类检索和迭代检索。</p><p>示例选择依据</p><ul><li><strong>相似性</strong>是指选出与待解决问题文本最为相近的示例。</li><li><strong>多样性</strong>则侧要求所选的示例涵盖尽量广的内容扩大演示示例对待解决问题的覆盖范围。</li></ul><p>直接检索</p><p>直接检索是目前应用广泛的示例选择策略。其工作原理是，在筛选示例时，检索器依据特定的评分标准对示例进行排序，然后选取排名靠前的K个示例。代表性方法是KATE。</p><ul><li>优点：相比于随机选取演示示例能大幅提升性能，简单有效。</li><li>缺点：未对示例的多样性进行考虑，选择出的示例可能趋向同质化。</li></ul><p>聚类检索</p><p>聚类检索策略把所有示例划分为K个簇，让相似的示例聚集在一起。而后从每个簇中选取最为相似的示例，最终获取K个示例。代表性方法是Self-Prompting。</p><ul><li>优点：能够有效提升多样性。</li><li>缺点：可能存在有些簇与问题并不相关，导致选择出不相关的示例。</li></ul><p>迭代检索</p><p>迭代检索策略中，检索过程是迭代的，下一个示例的选择依赖于当前的问题和已选的示例。代表性方法是RetICL。</p><ul><li>优点：兼顾了相似性多样性。</li><li>缺点：在计算上相对复杂，多轮迭代，速度慢，成本高。</li></ul><p>性能影响因素</p><p>上下文学习的性能受到多种因素的共同影响，这些因素包括预训练数据、预训练模型，以及演示示例等多个方面。</p><ul><li>预训练数据 <ul><li>领域丰富度</li><li>任务多样性</li><li>训练数据的分布特征</li></ul></li><li>预训练模型 <ul><li>参数规模</li></ul></li><li>演示示例 <ul><li>格式</li><li>输入-标签映射</li><li>示例数量</li></ul></li></ul>',24)])])}const c=e(p,[["render",o]]),s=JSON.parse(`{"path":"/ai/gm/llm/prompt/icl.html","title":"In-Context Learning 上下文学习","lang":"en-US","frontmatter":{"description":"In-Context Learning 上下文学习 上下文学习是大语言模型一种新的学习范式，它通过构造特定的Prompt,来使得语言模型理解并学习下游任务。相比于传统的监督微调，其不需要更新模型参数可以快速适应下游任务。 上下文学习通过任务说明，演示示例等信息引导模型输出，快速适应新任务，使语言模型即服务成为可能。监督微调需要构造训练集，通过更新模型参...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"In-Context Learning 上下文学习\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-12-12T20:39:51.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"],["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/gm/llm/prompt/icl.html"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"In-Context Learning 上下文学习"}],["meta",{"property":"og:description","content":"In-Context Learning 上下文学习 上下文学习是大语言模型一种新的学习范式，它通过构造特定的Prompt,来使得语言模型理解并学习下游任务。相比于传统的监督微调，其不需要更新模型参数可以快速适应下游任务。 上下文学习通过任务说明，演示示例等信息引导模型输出，快速适应新任务，使语言模型即服务成为可能。监督微调需要构造训练集，通过更新模型参..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-12-12T20:39:51.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-12T20:39:51.000Z"}]]},"git":{"createdTime":1765571991000,"updatedTime":1765571991000,"contributors":[{"name":"David Liu","username":"","email":"davidliu02k@gmail.com","commits":1}]},"readingTime":{"minutes":2.86,"words":857},"filePathRelative":"ai/gm/llm/prompt/icl.md","excerpt":"\\n<p>上下文学习是大语言模型一种新的学习范式，它通过构造特定的Prompt,来使得语言模型理解并学习下游任务。相比于传统的监督微调，其不需要更新模型参数可以快速适应下游任务。</p>\\n<p>上下文学习通过任务说明，演示示例等信息引导模型输出，快速适应新任务，使语言模型即服务成为可能。监督微调需要构造训练集，通过更新模型参数来适应下游任务，效果更好，但是成本高。</p>\\n<h3>为什么有效</h3>\\n<p>大语言模型在预训练阶段从大量文本中学习潜在的概念。当运用上下文学习进行推理时，其借助任务说明或演示示例来“锚定”其在预训练期间所习得的相关概念，从而进行上下文学习，并对问题进行预测。</p>","autoDesc":true}`);export{c as comp,s as data};
