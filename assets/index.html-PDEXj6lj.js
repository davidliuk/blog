import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as o,o as i}from"./app-isOblzBz.js";const n={};function p(l,e){return i(),a("div",null,e[0]||(e[0]=[o('<h1 id="visual-language-model" tabindex="-1"><a class="header-anchor" href="#visual-language-model"><span>Visual Language Model</span></a></h1><p>视觉基础模型</p><p>骨干网络：ViT、Moco v3</p><p>自监督基础模型：DINO(对比式)、MAE(生成式)</p><p>分割基础模型：SAM</p><ul><li>CLIP</li></ul><p>CV很多方法都是源于NLP的思路</p><p>图像 Encoder： DINO, MAE</p><p>图像文本Pair Encoder：CLIP</p>',9)]))}const d=t(n,[["render",p],["__file","index.html.vue"]]),m=JSON.parse(`{"path":"/ai/llm/vlm/","title":"Visual Language Model","lang":"en-US","frontmatter":{"description":"Visual Language Model 视觉基础模型 骨干网络：ViT、Moco v3 自监督基础模型：DINO(对比式)、MAE(生成式) 分割基础模型：SAM CLIP CV很多方法都是源于NLP的思路 图像 Encoder： DINO, MAE 图像文本Pair Encoder：CLIP","head":[["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/llm/vlm/"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"Visual Language Model"}],["meta",{"property":"og:description","content":"Visual Language Model 视觉基础模型 骨干网络：ViT、Moco v3 自监督基础模型：DINO(对比式)、MAE(生成式) 分割基础模型：SAM CLIP CV很多方法都是源于NLP的思路 图像 Encoder： DINO, MAE 图像文本Pair Encoder：CLIP"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-05-28T16:35:06.000Z"}],["meta",{"property":"article:modified_time","content":"2025-05-28T16:35:06.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Visual Language Model\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-05-28T16:35:06.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"]]},"headers":[],"git":{"createdTime":1748450106000,"updatedTime":1748450106000,"contributors":[{"name":"David","email":"l729641074@163.com","commits":1}]},"readingTime":{"minutes":0.21,"words":64},"filePathRelative":"ai/llm/vlm/README.md","localizedDate":"May 28, 2025","excerpt":"\\n<p>视觉基础模型</p>\\n<p>骨干网络：ViT、Moco v3</p>\\n<p>自监督基础模型：DINO(对比式)、MAE(生成式)</p>\\n<p>分割基础模型：SAM</p>\\n<ul>\\n<li>CLIP</li>\\n</ul>\\n<p>CV很多方法都是源于NLP的思路</p>\\n<p>图像 Encoder： DINO, MAE</p>\\n<p>图像文本Pair Encoder：CLIP</p>\\n","autoDesc":true}`);export{d as comp,m as data};
