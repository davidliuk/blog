import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,a as s,o as t}from"./app-BZLta1H5.js";const r={};function l(p,e){return t(),i("div",null,[...e[0]||(e[0]=[s('<h1 id="cluster-数据分片" tabindex="-1"><a class="header-anchor" href="#cluster-数据分片"><span>Cluster 数据分片</span></a></h1><p>Redis Cluster 通过分片（Sharding） 来进行数据管理，提供</p><ul><li>主从复制（Master-Slave Replication）、</li><li>故障转移（Failover）</li></ul><p>等开箱即用的功能，可以非常方便地帮助我们解决 Redis 大数据量缓存以及 Redis 服务高可用的问题。</p><p>虽说 Redis Cluster 可以扩展到 1000 个节点，但强烈不推荐这样做，应尽量避免集群中的节点过多。这是因为 Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，当节点过多时，Gossip 协议的效率会显著下降，通信成本剧增。</p><p>节点建议最多 1000 个节点</p><ul><li>Redis 集群支持多个 Master,每个 Master.又可以挂载多个 Slave</li><li>由于 Cluster 自带 Sentinel 的故障转移机制，内置了高可用的支持，无需再去使用哨兵功能</li><li>客户端与 Redis 的节点连接，♪ 不再需要连接集群中所有的节点，只需要任意连接集群中的一个可用节点即可</li><li>槽位 slot 负责分配到各个物理服务节点，由对应的集群来负责维护节点、插槽和数据之间的关系</li></ul><h2 id="集群算法" tabindex="-1"><a class="header-anchor" href="#集群算法"><span>集群算法</span></a></h2><ul><li>redis 集群的槽位 slot</li><li>redis 集群的分片</li><li>他两的优势</li><li>slot 槽位映射，一般业界有 3 种解决方案</li><li>经典面试题</li><li>为什么 redis 集群的最大槽数是 16384 个？</li><li>Redis 集群不保证强一致性，这意味着在特定的条件下，Redis 集群可能会丢掉一些被系统收到的写入请求命令</li><li>集群的密钥空间被分成 16384 个槽，有效地设置了 16384 个主节点</li><li>的集群大小上限（但是，建议的最大节点大小约为 1000 个节点）。</li></ul><p>哈希槽，CRC16 校验对 16384 取模</p><p>这种结构很容易添加或者删除节点。比如如果我想新添加个节点 D,我需要从节点 A,B,C 中得部分槽到 D 上。如果我想移除节点 A，需要将 A 中的槽移到 B 和 C 节点上，然后将没有任何槽的 A 节点从集群中移除即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态。</p><h2 id="哈希分区算法" tabindex="-1"><a class="header-anchor" href="#哈希分区算法"><span>哈希分区算法</span></a></h2><h3 id="哈希取余分区" tabindex="-1"><a class="header-anchor" href="#哈希取余分区"><span>哈希取余分区</span></a></h3><p>如果数量变动，就会故障不可用</p><h3 id="一致性哈希算法分区" tabindex="-1"><a class="header-anchor" href="#一致性哈希算法分区"><span>一致性哈希算法分区</span></a></h3><h4 id="步骤" tabindex="-1"><a class="header-anchor" href="#步骤"><span>步骤</span></a></h4><p>构建一致性<strong>哈希环</strong>：0-2^32-1</p><p>节点映射：redis 服务器 ip 节点映射</p><p>落键规则：当我们需要存储一个 kv 键值对时，首先计算 key 的 hash 值，hash(key),将这个 key 使用相同的函数 Hash 计算出哈希值并确定此数据在环上的位置从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器，并将该键值对存储在该节点上。</p><h4 id="优点" tabindex="-1"><a class="header-anchor" href="#优点"><span>优点</span></a></h4><p>容错性：只影响宕机的这一台的数据，且这些数据将来也会转移到下一台去存储</p><p>扩展性：增加节点不需要哈希重新计算</p><h4 id="缺点" tabindex="-1"><a class="header-anchor" href="#缺点"><span>缺点</span></a></h4><p>Hash 环的数据倾斜问题：一致性 Hsh 算法在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题</p><h2 id="哈希槽分区" tabindex="-1"><a class="header-anchor" href="#哈希槽分区"><span>哈希槽分区</span></a></h2><p>哈希槽实质就是一个数组，数组[0,2^14-1]形成 hash slot 空间。</p><p>解决均匀分配的问题，在数据和节点之间又加入了一层，把这层称为哈希槽(slot)，用于管理数据和节点之间的关系，现在就相当于节点上放的是槽，槽里放的是数据。</p><p>Redis Cluster 通常有 16384 个哈希槽，要计算给定 key 应该分布到哪个哈希槽中，我们只需要先对每个 key 计算 CRC-16（XMODEM） 校验码，然后再对这个校验码对 16384(哈希槽的总数) 取模，得到的值即是 key 对应的哈希槽。</p><h3 id="分槽个数" tabindex="-1"><a class="header-anchor" href="#分槽个数"><span>分槽个数</span></a></h3><p>在消息头中最占空间的是 myslots[CLUSTER SLOTS/8]。当槽位为 65536 时，这块的大小是：65536÷8÷1024=8kb</p><h3 id="为什么-16384" tabindex="-1"><a class="header-anchor" href="#为什么-16384"><span>为什么 16384</span></a></h3><p>如果槽位为 65536，发送心跳信息的消息头达 8k,发送的心跳包过于庞大。</p><p>在消息头中最占空间的是 myslots[CLUSTER SLOTS/8]。当槽位为 65536 时，这块的大小是：65536÷8÷1024=8kb<br> 在消息头中最占空间的是 myslots[CLUSTER SLOTS/8]。当槽位为 16384 时，这块的大小是：16384÷8÷1024=2kb<br> 因为每秒钟，redis 节点需要发送一定数量的 ping 消息作为心跳包，如果槽位为 65536，这个 ping 消息的消息头太大了，浪费带宽。</p><p>redis 的集群主节点数量基本不可能超过 1000 个。</p><p>集群节点越多，心跳包的消息体内携带的数据越多。如果节点过 1000 个，也会导致网络拥堵。因此 redis 作者不建议 redis cluster 节点数量超过 1000 个。那么，对于节点数在 1000 以内的 redis cluster 集群，16384 个槽位够用了。没有必要拓展到 65536 个。</p><h4 id="槽位越小-节点少的情况下-压缩比高-容易传输" tabindex="-1"><a class="header-anchor" href="#槽位越小-节点少的情况下-压缩比高-容易传输"><span>槽位越小，节点少的情况下，压缩比高，容易传输</span></a></h4><p>Redis 主节点的配置信息中它所负责的哈希槽是通过一张 bitmap 的形式来保存的，在传输过程中会对 bitmap 进行压缩，但是如果 bitmap 的填充率<br> slots/N 很高的话(N 表示节点数)，bitmap 的压缩率就很低。如果节点数很少，而哈希槽数量很多的话，bitmap 的压缩率就很低。</p><h3 id="扩缩容" tabindex="-1"><a class="header-anchor" href="#扩缩容"><span>扩缩容</span></a></h3><h3 id="不保证强一致性" tabindex="-1"><a class="header-anchor" href="#不保证强一致性"><span>不保证强一致性</span></a></h3><p>节点挂了会写丢失</p><h2 id="通信" tabindex="-1"><a class="header-anchor" href="#通信"><span>通信</span></a></h2><p>Gossip 协议</p><p>Redis Cluster 是一个典型的分布式系统，分布式系统中的各个节点需要互相通信。既然要相互通信就要遵循一致的通信协议，Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息。</p><p>Redis Cluster 的节点之间会相互发送多种 Gossip 消息：</p><ul><li>MEET ：在 Redis Cluster 中的某个 Redis 节点上执行 CLUSTER MEET ip port 命令，可以向指定的 Redis 节点发送一条 MEET 信息，用于将其添加进 Redis Cluster 成为新的 Redis 节点。</li><li>PING/PONG ：Redis Cluster 中的节点都会定时地向其他节点发送 PING 消息，来交换各个节点状态信息，检查各个节点状态，包括在线状态、疑似下线状态 PFAIL 和已下线状态 FAIL。</li><li>FAIL ：Redis Cluster 中的节点 A 发现 B 节点 PFAIL ，并且在下线报告的有效期限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 。</li></ul>',45)])])}const h=a(r,[["render",l]]),o=JSON.parse(`{"path":"/se/database/redis/availability/sharding.html","title":"Cluster 数据分片","lang":"en-US","frontmatter":{"description":"Cluster 数据分片 Redis Cluster 通过分片（Sharding） 来进行数据管理，提供 主从复制（Master-Slave Replication）、 故障转移（Failover） 等开箱即用的功能，可以非常方便地帮助我们解决 Redis 大数据量缓存以及 Redis 服务高可用的问题。 虽说 Redis Cluster 可以扩展到 ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Cluster 数据分片\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-12-12T20:39:51.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"],["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/se/database/redis/availability/sharding.html"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"Cluster 数据分片"}],["meta",{"property":"og:description","content":"Cluster 数据分片 Redis Cluster 通过分片（Sharding） 来进行数据管理，提供 主从复制（Master-Slave Replication）、 故障转移（Failover） 等开箱即用的功能，可以非常方便地帮助我们解决 Redis 大数据量缓存以及 Redis 服务高可用的问题。 虽说 Redis Cluster 可以扩展到 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-12-12T20:39:51.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-12T20:39:51.000Z"}]]},"git":{"createdTime":1765571991000,"updatedTime":1765571991000,"contributors":[{"name":"David Liu","username":"","email":"davidliu02k@gmail.com","commits":1}]},"readingTime":{"minutes":5.88,"words":1764},"filePathRelative":"se/database/redis/availability/sharding.md","excerpt":"\\n<p>Redis Cluster 通过分片（Sharding） 来进行数据管理，提供</p>\\n<ul>\\n<li>主从复制（Master-Slave Replication）、</li>\\n<li>故障转移（Failover）</li>\\n</ul>\\n<p>等开箱即用的功能，可以非常方便地帮助我们解决 Redis 大数据量缓存以及 Redis 服务高可用的问题。</p>\\n<p>虽说 Redis Cluster 可以扩展到 1000 个节点，但强烈不推荐这样做，应尽量避免集群中的节点过多。这是因为 Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，当节点过多时，Gossip 协议的效率会显著下降，通信成本剧增。</p>","autoDesc":true}`);export{h as comp,o as data};
