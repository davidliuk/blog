import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,a as t,o as l}from"./app-B_TQ4tbw.js";const o={};function n(r,e){return l(),i("div",null,e[0]||(e[0]=[t('<h1 id="multimodal-large-language-model" tabindex="-1"><a class="header-anchor" href="#multimodal-large-language-model"><span>Multimodal Large Language Model</span></a></h1><p>Visual Language Model</p><p>视觉基础模型</p><p>骨干网络：ViT、MoCo v3</p><p>自监督基础模型：DINO(对比式)、MAE(生成式)</p><p>分割基础模型：SAM</p><ul><li>CLIP</li></ul><p>CV很多方法都是源于NLP的思路</p><ul><li><p>图像 Encoder: DINO, MAE</p></li><li><p>图像文本 Pair Encoder：CLIP</p></li></ul><hr><p>自监督学习 (Self-supervised Learning)</p><p>定义：Predict parts of input data from other parts, using the data&#39;s inherent structure instead of explicit labels</p><ul><li>基于前置任务 <ul><li>位置预测（上下文）</li><li>旋转预测</li><li>上色</li><li>聚类预测</li></ul></li><li>基于对比学习 <ul><li>创建pair样本</li></ul></li><li>基于掩码重建</li></ul><p><img src="https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250705104155396.png" alt="image-20250705104155396" loading="lazy"></p>',14)]))}const g=a(o,[["render",n],["__file","index.html.vue"]]),m=JSON.parse(`{"path":"/ai/llm/mllm/","title":"Multimodal Large Language Model","lang":"en-US","frontmatter":{"description":"Multimodal Large Language Model Visual Language Model 视觉基础模型 骨干网络：ViT、MoCo v3 自监督基础模型：DINO(对比式)、MAE(生成式) 分割基础模型：SAM CLIP CV很多方法都是源于NLP的思路 图像 Encoder: DINO, MAE 图像文本 Pair Encoder...","head":[["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/llm/mllm/"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"Multimodal Large Language Model"}],["meta",{"property":"og:description","content":"Multimodal Large Language Model Visual Language Model 视觉基础模型 骨干网络：ViT、MoCo v3 自监督基础模型：DINO(对比式)、MAE(生成式) 分割基础模型：SAM CLIP CV很多方法都是源于NLP的思路 图像 Encoder: DINO, MAE 图像文本 Pair Encoder..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250705104155396.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-08-17T07:52:28.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-17T07:52:28.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Multimodal Large Language Model\\",\\"image\\":[\\"https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250705104155396.png\\"],\\"dateModified\\":\\"2025-08-17T07:52:28.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"]]},"headers":[],"git":{"createdTime":1755417148000,"updatedTime":1755417148000,"contributors":[{"name":"dawei.liu","email":"dawei.liu@bytedance.com","commits":1}]},"readingTime":{"minutes":0.47,"words":141},"filePathRelative":"ai/llm/mllm/README.md","localizedDate":"August 17, 2025","excerpt":"\\n<p>Visual Language Model</p>\\n<p>视觉基础模型</p>\\n<p>骨干网络：ViT、MoCo v3</p>\\n<p>自监督基础模型：DINO(对比式)、MAE(生成式)</p>\\n<p>分割基础模型：SAM</p>\\n<ul>\\n<li>CLIP</li>\\n</ul>\\n<p>CV很多方法都是源于NLP的思路</p>\\n<ul>\\n<li>\\n<p>图像 Encoder: DINO, MAE</p>\\n</li>\\n<li>\\n<p>图像文本 Pair Encoder：CLIP</p>\\n</li>\\n</ul>\\n<hr>\\n<p>自监督学习 (Self-supervised Learning)</p>","autoDesc":true}`);export{g as comp,m as data};
