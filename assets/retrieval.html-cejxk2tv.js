import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a as t,o as i}from"./app-C_tIvXCt.js";const n={};function l(p,a){return i(),e("div",null,a[0]||(a[0]=[t('<h1 id="召回" tabindex="-1"><a class="header-anchor" href="#召回"><span>召回</span></a></h1><ul><li>推荐系统有几十条召回通道，它们的召回总量是固定的。总量越大，指标越好，粗排计算量越大。</li><li>双塔模型(two-tower)和item-to-item(I2I)是最重要的两类召回模型，占据召回的大部分配额</li><li>有很多小众的模型，占据的配额很少。在召回总量不变的前提下，添加某些召回模型可以提升核心指标</li><li>有很多内容池，比如30天物品、1天物品、6小时物品、新用户优质内容池、分人群内容池。</li><li>同一个模型可以用于多个内容池，得到多条召回通道。 <ul><li>每个通道需要一个ANN索引、ANN检索</li></ul></li></ul><h2 id="双塔模型" tabindex="-1"><a class="header-anchor" href="#双塔模型"><span>双塔模型</span></a></h2><h3 id="方向1-优化正样本、负样本" tabindex="-1"><a class="header-anchor" href="#方向1-优化正样本、负样本"><span>方向1：优化正样本、负样本</span></a></h3><ul><li>简单正样本：有点击的（用户，物品)二元组。</li><li>简单负样本：随机组合的（用户，物品)二元组</li><li>困难负样本：排序靠后的（用户，物品)二元组</li></ul><h3 id="方向2-改进神经网络结构" tabindex="-1"><a class="header-anchor" href="#方向2-改进神经网络结构"><span>方向2：改进神经网络结构</span></a></h3><ul><li>Baseline：用户塔、物品塔分别是全连接网络，各输出一个向量，分别作为用户、物品的表征。</li><li>改进：用户塔、物品塔分别用DCN代替全连接网络。</li><li>改进：在用户塔中使用用户行为序列(last-n)。</li><li>改进：使用多向量模型代替单向量模型。（标准的双塔模型也叫单向量模型。)</li></ul><h3 id="方向3-改进模型的训练方法" tabindex="-1"><a class="header-anchor" href="#方向3-改进模型的训练方法"><span>方向3：改进模型的训练方法</span></a></h3><ul><li>Baseline：做二分类，让模型学会区分正样本和负样本。</li><li>改进：结合二分类、batch内负采样。（对于batch内负采样，需要做纠偏。)</li><li>改进：使用自监督学习方法，让冷门物品的embedding学得更好</li></ul><h2 id="item-to-ltem-i2i" tabindex="-1"><a class="header-anchor" href="#item-to-ltem-i2i"><span>Item-to-ltem (I2I)</span></a></h2><ul><li>I2I是一大类模型，基于相似物品做召回。</li><li>最常见的用法是U2I2I(user→item&gt;item) <ul><li>·用户u喜欢物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（用户历史上交互过的物品)</li><li>·寻找<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的相似物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（即I2I)。</li><li>·将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>推荐给u。</li></ul></li><li>如何计算物品相似度？</li><li>方法1：ItemCF及其变体。 <ul><li>·一些用户同时喜欢物品i1和i2’则认为i1和i2相似。</li><li>ItemCF、Online ItemCF、Swing、Online Swing都是基于相同的思想</li><li>·线上同时使用上述4种2I模型，各分配一定配额·</li></ul></li><li>方法2：基于物品向量表征，计算向量相似度。（双塔模<br> 型、图神经网络均可计算物品向量表征。)</li></ul><h2 id="类似i2i的模型" tabindex="-1"><a class="header-anchor" href="#类似i2i的模型"><span>类似I2I的模型</span></a></h2><ul><li>U2U2I(user→user→item)：已知用户u1与2相似，且u2喜欢物品i’那么给用户u1推荐物品i。</li><li>U2A2I(user&gt;author→item)：已知用户u喜欢作者a，且a发布物品i，那么给用户u推荐物品i。</li><li>U2A2A2I(user&gt;author&gt;author&gt;item):已知用户u喜欢作者a1’且a1与a2相似’a2发布物品i,那么给用户u推荐物品i。</li></ul><h2 id="更复杂的模型" tabindex="-1"><a class="header-anchor" href="#更复杂的模型"><span>更复杂的模型</span></a></h2><ul><li>Path-based Deep Network (PDN)[1]</li><li>Deep Retrieval [2]</li><li>Sparse-Interest Network (SINE)[3]</li><li>Multi-task Multi-view Graph Representation Learning (M2GRL)[4]</li></ul><p>参考文献</p><ol><li>Li et al.Path-based Deep Network for Candidate Item Matching in <a href="http://Recommenders.In" target="_blank" rel="noopener noreferrer">Recommenders.In</a> S/G/R,2021.</li><li>Gao et al.Learning an end-to-end structure for retrieval in large-scale <a href="http://recommendations.In" target="_blank" rel="noopener noreferrer">recommendations.In</a> C/KM, 2021.</li><li>Tan et al.Sparse-interest network for sequential <a href="http://recommendation.In" target="_blank" rel="noopener noreferrer">recommendation.In</a> WSDM,2021.</li><li>Wang et al.M2GRL:A multitask multi-view graph representation learning framework for web-scale recommender <a href="http://systems.In" target="_blank" rel="noopener noreferrer">systems.In</a> KDD,2020.</li></ol><p>总结：改进召回模型</p><ul><li>双塔模型：优化正负样本、改进神经网络结构、改进训练的方法。</li><li>I2I模型：同时使用ItemCF及其变体、使用物品向量表征计算物品相似度。</li><li>添加小众的召回模型，比如PDN、Deep Retrieval、SINE、M2GRL等模型</li><li>在召回总量不变的前提下，调整各召回通道的配额。（可以让各用户群体用不同的配额。)</li></ul>',19)]))}const o=s(n,[["render",l],["__file","retrieval.html.vue"]]),c=JSON.parse(`{"path":"/ai/rec/metrics/retrieval.html","title":"召回","lang":"en-US","frontmatter":{"description":"召回 推荐系统有几十条召回通道，它们的召回总量是固定的。总量越大，指标越好，粗排计算量越大。 双塔模型(two-tower)和item-to-item(I2I)是最重要的两类召回模型，占据召回的大部分配额 有很多小众的模型，占据的配额很少。在召回总量不变的前提下，添加某些召回模型可以提升核心指标 有很多内容池，比如30天物品、1天物品、6小时物品、新用...","head":[["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/rec/metrics/retrieval.html"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"召回"}],["meta",{"property":"og:description","content":"召回 推荐系统有几十条召回通道，它们的召回总量是固定的。总量越大，指标越好，粗排计算量越大。 双塔模型(two-tower)和item-to-item(I2I)是最重要的两类召回模型，占据召回的大部分配额 有很多小众的模型，占据的配额很少。在召回总量不变的前提下，添加某些召回模型可以提升核心指标 有很多内容池，比如30天物品、1天物品、6小时物品、新用..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-08-31T05:52:07.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-31T05:52:07.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"召回\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-31T05:52:07.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"]]},"headers":[{"level":2,"title":"双塔模型","slug":"双塔模型","link":"#双塔模型","children":[{"level":3,"title":"方向1：优化正样本、负样本","slug":"方向1-优化正样本、负样本","link":"#方向1-优化正样本、负样本","children":[]},{"level":3,"title":"方向2：改进神经网络结构","slug":"方向2-改进神经网络结构","link":"#方向2-改进神经网络结构","children":[]},{"level":3,"title":"方向3：改进模型的训练方法","slug":"方向3-改进模型的训练方法","link":"#方向3-改进模型的训练方法","children":[]}]},{"level":2,"title":"Item-to-ltem (I2I)","slug":"item-to-ltem-i2i","link":"#item-to-ltem-i2i","children":[]},{"level":2,"title":"类似I2I的模型","slug":"类似i2i的模型","link":"#类似i2i的模型","children":[]},{"level":2,"title":"更复杂的模型","slug":"更复杂的模型","link":"#更复杂的模型","children":[]}],"git":{"createdTime":1756619527000,"updatedTime":1756619527000,"contributors":[{"name":"dawei.liu","email":"dawei.liu@bytedance.com","commits":1}]},"readingTime":{"minutes":3.1,"words":930},"filePathRelative":"ai/rec/metrics/retrieval.md","localizedDate":"August 31, 2025","excerpt":"\\n<ul>\\n<li>推荐系统有几十条召回通道，它们的召回总量是固定的。总量越大，指标越好，粗排计算量越大。</li>\\n<li>双塔模型(two-tower)和item-to-item(I2I)是最重要的两类召回模型，占据召回的大部分配额</li>\\n<li>有很多小众的模型，占据的配额很少。在召回总量不变的前提下，添加某些召回模型可以提升核心指标</li>\\n<li>有很多内容池，比如30天物品、1天物品、6小时物品、新用户优质内容池、分人群内容池。</li>\\n<li>同一个模型可以用于多个内容池，得到多条召回通道。\\n<ul>\\n<li>每个通道需要一个ANN索引、ANN检索</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}`);export{o as comp,c as data};
