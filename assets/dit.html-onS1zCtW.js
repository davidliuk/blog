import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a as o,o as n}from"./app-BtADw1TI.js";const a={};function r(l,i){return n(),e("div",null,[...i[0]||(i[0]=[o('<h1 id="dit" tabindex="-1"><a class="header-anchor" href="#dit"><span>DiT</span></a></h1><blockquote><p>Diffusion Transformer</p></blockquote><p>传统扩散模型的问题</p><ol><li>背景崩坏</li><li>角色脸盲</li></ol><p>传统方法：U-Net</p><p>CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙</p><h2 id="dydit" tabindex="-1"><a class="header-anchor" href="#dydit"><span>DyDiT</span></a></h2><ol><li>时间步动态宽度（TDW），轻量级路由器</li><li>空间动态令牌（SDT）</li></ol><h2 id="mmdit" tabindex="-1"><a class="header-anchor" href="#mmdit"><span>MMDiT</span></a></h2><p>SD3</p><ul><li>DiT:架构从&quot;U-Net&quot;到”Transformer&#39;”的跨越</li><li>DyDiT:计算从“静态”到“动态”的优化</li><li>MMDT:模态从“单模态”到&quot;多模态深度交互”的升级</li></ul>',11)])])}const d=t(a,[["render",r]]),m=JSON.parse(`{"path":"/ai/gm/visual/diffusion/dit.html","title":"DiT","lang":"en-US","frontmatter":{"description":"DiT Diffusion Transformer 传统扩散模型的问题 背景崩坏 角色脸盲 传统方法：U-Net CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙 DyDiT 时间步动态宽度（TDW），轻量级路由器 空间动态令牌（SDT） MMDiT SD3 DiT:架构从\\"U-Net\\"到”Transformer'”的跨越 DyDiT:计算从...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"DiT\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-12-15T23:09:49.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"],["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/gm/visual/diffusion/dit.html"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"DiT"}],["meta",{"property":"og:description","content":"DiT Diffusion Transformer 传统扩散模型的问题 背景崩坏 角色脸盲 传统方法：U-Net CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙 DyDiT 时间步动态宽度（TDW），轻量级路由器 空间动态令牌（SDT） MMDiT SD3 DiT:架构从\\"U-Net\\"到”Transformer'”的跨越 DyDiT:计算从..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-12-15T23:09:49.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-15T23:09:49.000Z"}]]},"git":{"createdTime":1765840189000,"updatedTime":1765840189000,"contributors":[{"name":"David Liu","username":"","email":"davidliu02k@gmail.com","commits":1}]},"readingTime":{"minutes":0.4,"words":121},"filePathRelative":"ai/gm/visual/diffusion/dit.md","excerpt":"\\n<blockquote>\\n<p>Diffusion Transformer</p>\\n</blockquote>\\n<p>传统扩散模型的问题</p>\\n<ol>\\n<li>背景崩坏</li>\\n<li>角色脸盲</li>\\n</ol>\\n<p>传统方法：U-Net</p>\\n<p>CNN方法缺乏长距离依赖建模能力，导致高分辨率图片细节粗糙</p>\\n<h2>DyDiT</h2>\\n<ol>\\n<li>时间步动态宽度（TDW），轻量级路由器</li>\\n<li>空间动态令牌（SDT）</li>\\n</ol>\\n<h2>MMDiT</h2>\\n<p>SD3</p>\\n<ul>\\n<li>DiT:架构从\\"U-Net\\"到”Transformer'”的跨越</li>\\n<li>DyDiT:计算从“静态”到“动态”的优化</li>\\n<li>MMDT:模态从“单模态”到\\"多模态深度交互”的升级</li>\\n</ul>","autoDesc":true}`);export{d as comp,m as data};
