import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,a,o as p}from"./app-wjKRSZHj.js";const o={};function l(r,e){return p(),t("div",null,e[0]||(e[0]=[a('<h1 id="参数微调" tabindex="-1"><a class="header-anchor" href="#参数微调"><span>参数微调</span></a></h1><p><a href="https://www.bilibili.com/video/BV1mRwAeSEnL?spm_id_from=333.788.videopod.sections&amp;vd_source=086ba9e7e990dd00adb3a485b6f48804" target="_blank" rel="noopener noreferrer">https://www.bilibili.com/video/BV1mRwAeSEnL?spm_id_from=333.788.videopod.sections&amp;vd_source=086ba9e7e990dd00adb3a485b6f48804</a></p><p>下游任务适配</p><p>预训练模型难以直接适配到下游任务。</p><p>预训练模型：倾向于续写或复读一句话</p><p>通过上下文学习，可以在一定程度上适配到下游任务。</p><p>上下文学习：能够模仿示例内容完成任务</p><p>上下文学习的不足</p><p>尽管上下文学习能有效利用大模型的能力，但其性能和效率方面仍存在一些局限性</p><h3 id="指令微调" tabindex="-1"><a class="header-anchor" href="#指令微调"><span>指令微调</span></a></h3><p>为了保证下游任务性能，语言模型需要定制化调整以完成下游任务适配。</p><h3 id="指令数据" tabindex="-1"><a class="header-anchor" href="#指令数据"><span>指令数据</span></a></h3><p>指令数据通常包含指令（任务描述）、示例（可选）、问题和回答。通常构造指令数据集有两种方式：(1)数据集成；(2)大语言模型生成。</p><p>监督微调(SFT)</p><p>基于构造的指令数据集，对大模型进行监督微调(Supervised Fine-Tuning)。对于现有大语言模型，通常以自回归方式进行训练。</p><blockquote><p>Teacher forcing</p></blockquote><h2 id="全量监督微调的挑战-fft" tabindex="-1"><a class="header-anchor" href="#全量监督微调的挑战-fft"><span>全量监督微调的挑战 FFT</span></a></h2><p>然而，由于全量监督微调需要更新所有模型参数，当面对拥有庞大参数量的大模型时，全量监督微调会消耗大量存储和计算资源。</p><ul><li>GPU内存不足</li><li>全量微调效率低</li></ul><h2 id="参数高效微调-peft" tabindex="-1"><a class="header-anchor" href="#参数高效微调-peft"><span>参数高效微调 PEFT</span></a></h2><p><img src="https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250615225453183.png" alt="image-20250615225453183" loading="lazy"></p><p>为了解决全量微调的问题，参数高效微调(Parameter-Efficient Fine-Tuning,PEFT)避免更新全部参数，在保证微调性能的同时，减少更新的参数数量和计算开销。</p><p>参数高效微调的优势</p><p>PEFT技术主要有三个方面的优势：</p><ul><li><p>计算效率：全量微调和参数高效微调显存占用对比。其中，PEFT方法减少了需要更新的参数数量，显著减少了训练时的计算资源。</p></li><li><p>存储效率：PEFT方法仅需要保留部分微调参数，显著降低了微调模型的存储空间，尤其适用于存储受限的设备。</p><p>eg. LoRA rank=32, &lt;100MB</p></li><li><p>适应性强：参数高效微调技术在降低微调成本的同时，保证微调性能不受影响。且使模型可以快速适应不同任务，具有很好的灵活性。</p></li></ul><p>主流PEFT方法可分为三类：</p><ul><li>参数附加方法</li><li>参数选择方法</li><li>低秩适配方法</li></ul><p><img src="https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250615225839329.png" alt="image-20250615225839329" loading="lazy"></p>',28)]))}const s=i(o,[["render",l],["__file","index.html.vue"]]),m=JSON.parse(`{"path":"/ai/llm/ft/","title":"参数微调","lang":"en-US","frontmatter":{"description":"参数微调 https://www.bilibili.com/video/BV1mRwAeSEnL?spm_id_from=333.788.videopod.sections&vd_source=086ba9e7e990dd00adb3a485b6f48804 下游任务适配 预训练模型难以直接适配到下游任务。 预训练模型：倾向于续写或复读一句话 通过上下...","head":[["meta",{"property":"og:url","content":"https://davidliuk.github.io/blog/blog/ai/llm/ft/"}],["meta",{"property":"og:site_name","content":"David's Blog"}],["meta",{"property":"og:title","content":"参数微调"}],["meta",{"property":"og:description","content":"参数微调 https://www.bilibili.com/video/BV1mRwAeSEnL?spm_id_from=333.788.videopod.sections&vd_source=086ba9e7e990dd00adb3a485b6f48804 下游任务适配 预训练模型难以直接适配到下游任务。 预训练模型：倾向于续写或复读一句话 通过上下..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250615225453183.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-08-17T07:52:28.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-17T07:52:28.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"参数微调\\",\\"image\\":[\\"https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250615225453183.png\\",\\"https://gcore.jsdelivr.net/gh/davidliuk/images@master/image-20250615225839329.png\\"],\\"dateModified\\":\\"2025-08-17T07:52:28.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"David Liu\\",\\"url\\":\\"https://github.com/davidliuk\\"}]}"]]},"headers":[{"level":3,"title":"指令微调","slug":"指令微调","link":"#指令微调","children":[]},{"level":3,"title":"指令数据","slug":"指令数据","link":"#指令数据","children":[]},{"level":2,"title":"全量监督微调的挑战 FFT","slug":"全量监督微调的挑战-fft","link":"#全量监督微调的挑战-fft","children":[]},{"level":2,"title":"参数高效微调 PEFT","slug":"参数高效微调-peft","link":"#参数高效微调-peft","children":[]}],"git":{"createdTime":1755417148000,"updatedTime":1755417148000,"contributors":[{"name":"dawei.liu","email":"dawei.liu@bytedance.com","commits":1}]},"readingTime":{"minutes":2.06,"words":619},"filePathRelative":"ai/llm/ft/README.md","localizedDate":"August 17, 2025","excerpt":"\\n<p><a href=\\"https://www.bilibili.com/video/BV1mRwAeSEnL?spm_id_from=333.788.videopod.sections&amp;vd_source=086ba9e7e990dd00adb3a485b6f48804\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://www.bilibili.com/video/BV1mRwAeSEnL?spm_id_from=333.788.videopod.sections&amp;vd_source=086ba9e7e990dd00adb3a485b6f48804</a></p>","autoDesc":true}`);export{s as comp,m as data};
